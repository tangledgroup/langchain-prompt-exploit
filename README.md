# langchain-prompt-exploit

No local/remote LLM models are required for exploit to work.

## langchain 0.0.224

Check `0_langchain_prompt_wikipedia/README.md` for instructions.

## langchain 0.0.312 (Oct 12 2023)

Check `1_langchain_prompt_wikipedia/README.md` for instructions.

## References

* [Langchain](https://langchain.com)
* [Tangled Group, Inc](https://tangledgroup.com)
* https://security.snyk.io/vuln/SNYK-PYTHON-LANGCHAIN-5725807
* https://github.com/langchain-ai/langchain/issues/4849
* https://github.com/langchain-ai/langchain/blob/44da27c07b2bd0ccac355c8236a3ab1dd26870eb/libs/langchain/langchain/prompts/loading.py
* https://github.com/langchain-ai/langchain/blob/79fb90aafd104ce013b954936f0159e96d3ae85d/langchain/prompts/loading.py
* https://python.langchain.com/docs/integrations/tools/wikipedia
* https://github.com/NVIDIA/NeMo-Guardrails